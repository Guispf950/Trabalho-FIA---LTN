# Projeto 3: Racioc√≠nio Espacial Neuro-Simb√≥lico com Logic Tensor Networks (LTN)

**Disciplina:** Fundamentos de Intelig√™ncia Artificial (FIA)

**Professor:** Edjard Mota

## üë• Equipe
- ANDR√â MALMSTEEN OLIVEIRA AMORIM
- BENJAMIM ISAAC RIBEIRO LIMA
- DIEGO GABRIEL SILVA AZEVEDO
- GUILHERME DA SILVA PEREIRA
- LET√çCIA ARA√öJO
- MANFRED LIMA VEIGA

---

# üß† Racioc√≠nio Espacial Neuro-Simb√≥lico com Logic Tensor Networks (LTN)

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)
![LTN](https://img.shields.io/badge/AI-Neuro--Symbolic-green)
![Status](https://img.shields.io/badge/Status-Conclu√≠do-success)

Este projeto implementa um agente **Neuro-Simb√≥lico** capaz de aprender e raciocinar sobre rela√ß√µes espaciais (esquerda, direita, abaixo, empilhamento) em um ambiente 2D simplificado.

Diferente de redes neurais tradicionais "caixa-preta", este modelo utiliza **Logic Tensor Networks (LTN)** para aprender conceitos guiados por uma base de conhecimento rigorosa composta por **20 axiomas l√≥gicos**.

---

## üìë Sum√°rio
1. [Vis√£o Geral e Objetivo](#-vis√£o-geral-e-objetivo)
2. [Estrutura dos Dados (CLEVR-Simplified)](#-estrutura-dos-dados)
3. [Predicados (O Vocabul√°rio do Modelo)](#-predicados-o-vocabul√°rio-do-modelo)
4. [Os 20 Axiomas L√≥gicos (As Regras do Jogo)](#-os-20-axiomas-l√≥gicos-as-regras-do-jogo)
5. [Metodologia de Treino e Teste](#-metodologia-de-treino-e-teste)
6. [An√°lise Aprofundada dos Resultados](#-an√°lise-aprofundada-dos-resultados)
7. [Como Executar](#-como-executar)

---

## üî≠ Vis√£o Geral e Objetivo

O objetivo deste trabalho √© integrar o aprendizado profundo (Deep Learning) com a l√≥gica formal. O sistema deve:
1.  Receber vetores num√©ricos representando objetos geom√©tricos.
2.  Aprender o significado de conceitos espaciais (`LeftOf`, `Below`, etc.) sem r√≥tulos supervisionados diretos, apenas satisfazendo regras l√≥gicas.
3.  Responder a perguntas complexas (Queries) sobre o cen√°rio.

---

## üíæ Estrutura dos Dados

O ambiente simula objetos geom√©tricos com vetores de **11 dimens√µes**:
* `[0, 1]`: Coordenadas X, Y (normalizadas 0.0 a 1.0).
* `[2, 3, 4]`: One-hot vector para cores (**Vermelho, Verde, Azul**).
* `[5, 6, 7, 8, 9]`: One-hot vector para formas (**C√≠rculo, Quadrado, Cilindro, Cone, Tri√¢ngulo**).
* `[10]`: Tamanho (Cont√≠nuo: 0.0 a 1.0).

---

## üó£ Predicados (O Vocabul√°rio do Modelo)

Os predicados s√£o as "palavras" que a IA usa para descrever o mundo. Eles s√£o mapeados para redes neurais (MLP) ou fun√ß√µes l√≥gicas.

### Predicados Un√°rios (Atributos)
Verificam propriedades de um √∫nico objeto ($P(x) \rightarrow [0,1]$):
* **Formas:** `IsCircle(x)`, `IsSquare(x)`, `IsCylinder(x)`, `IsCone(x)`, `IsTriangle(x)`.
* **Cores:** `IsRed(x)`, `IsGreen(x)`, `IsBlue(x)`.
* **Tamanho:** `IsSmall(x)`, `IsLarge(x)`.

### Predicados Bin√°rios (Rela√ß√µes)
Verificam a rela√ß√£o entre dois objetos ($R(x,y) \rightarrow [0,1]$):
* **Espaciais Horizontais:** `LeftOf(x,y)`, `RightOf(x,y)`.
* **Espaciais Verticais:** `Below(x,y)` (Abaixo), `Above(x,y)` (Acima).
* **F√≠sicos/Outros:**
    * `CloseTo(x,y)`: Baseado na dist√¢ncia Euclidiana (Gaussiana).
    * `SameSize(x,y)`: Verifica similaridade de tamanho.
    * `CanStack(x,y)`: Verifica se $x$ pode ser empilhado sobre $y$.

### Predicados Tern√°rios
* **Posicional:** `InBetween(x, y, z)`: Verifica se o objeto $x$ est√° espacialmente entre $y$ e $z$.

---

## üìú Os 20 Axiomas L√≥gicos (As Regras do Jogo)

O cora√ß√£o do sistema. O modelo √© treinado para maximizar a verdade destas 20 regras simultaneamente.

### üîπ Grupo 1: Taxonomia e F√≠sica B√°sica
1.  **Exclusividade de Forma:** Cones n√£o podem ser Quadrados. ($\forall x, Cone(x) \rightarrow \neg Square(x)$).
2.  **Tamanho de Forma:** Todo Cone √© considerado Grande.
3.  **Restri√ß√£o de Cor:** C√≠rculos n√£o podem ser Vermelhos.
4.  **Sem√¢ntica de Cor:** Objetos Vermelhos e Verdes nunca est√£o Pr√≥ximos (`CloseTo`).
5.  **Tamanho Disjuntivo:** Tri√¢ngulos s√£o ou Pequenos ou Grandes.

### üîπ Grupo 2: Rela√ß√µes Espaciais (Horizontal/Vertical)
6.  **Existencial Vertical:** Todo Quadrado Azul tem algum Verde abaixo dele.
7.  **Existencial Horizontal:** Todo Quadrado tem algo √† sua direita (est√° √† esquerda de algu√©m).
8.  **Restri√ß√£o de Posi√ß√£o:** Se um objeto est√° `InBetween` (entre outros), ele n√£o pode ser um Tri√¢ngulo.
9.  **Defini√ß√£o de InBetween:** Estar entre $y$ e $z$ significa estar √† esquerda de um e √† direita do outro.
10. **Inversa:** `LeftOf(x,y)` √© equivalente a `RightOf(y,x)`.

### üîπ Grupo 3: Queries Complexas (O Desafio)
11. **Query Q1 (Composta):** Existe objeto Pequeno que est√° Abaixo de um Cilindro E √† Esquerda de um Quadrado?
12. **Query Q2 (Absoluta):** Existe um Cone Verde entre dois objetos quaisquer?
13. **Query Q3 (Regra Aprendida):** Se dois tri√¢ngulos est√£o pr√≥ximos, eles *devem* ter o mesmo tamanho.

### üîπ Grupo 4: Axiomas Estruturais (Rigor L√≥gico)
   Para garantir que a IA n√£o "alucine" rela√ß√µes imposs√≠veis:

14. **Irreflexividade:** Nada est√° √† esquerda de si mesmo `¬¨LeftOf(x,x)`.
15. **Assimetria Horizontal:** Se x est√° √† esquerda de y, y **n√£o** pode estar √† esquerda de x.
16. **Transitividade Horizontal:** Se x < y e y < z, ent√£o x < z.
17. **Transitividade Vertical:** Se x est√° abaixo de y e y abaixo de z, ent√£o x abaixo de z.

### üîπ Grupo 5: Defini√ß√µes Avan√ßadas
18. **LastOnTheLeft:** Define o conceito de "objeto mais √† esquerda de todos".
19. **LastOnTheRight:** Define o conceito de "objeto mais √† direita de todos".
20. **CanStack (Empilhamento):** Define que $x$ pode empilhar em $y$ somente se a base $y$ for est√°vel (Quadrado/Cilindro) e houver equil√≠brio.

---

## üî¨ Metodologia de Treino e Teste

Para cumprir os requisitos pedag√≥gicos da disciplina:

1.  **Treino Est√°tico (Static Scene):** O modelo treina em um √∫nico cen√°rio fixo (25 objetos com posi√ß√µes imut√°veis). Isso for√ßa a rede a aprender as *regras* l√≥gicas abstratas, j√° que n√£o h√° varia√ß√£o de dados para memorizar estatisticamente.
2.  **Teste Aleat√≥rio (Random Scenes):** O modelo treinado √© avaliado em 5 cen√°rios gerados totalmente ao acaso. O sucesso aqui prova a **generaliza√ß√£o**.

---

## üìä An√°lise Aprofundada dos Resultados

O experimento foi conduzido sob uma metodologia rigorosa para garantir que a rede neural n√£o apenas memorizasse o cen√°rio, mas aprendesse a **l√≥gica espacial subjacente**.

* **Treinamento:** 1 Cen√°rio Est√°tico (Overfitting for√ßado em regras).
* **Teste:** 5 Cen√°rios Aleat√≥rios Independentes (Teste de Generaliza√ß√£o).

Abaixo, apresentamos a m√©dia consolidada das 5 execu√ß√µes e a interpreta√ß√£o fenomenol√≥gica dos dados.

### 1. Tabela Consolidada de M√©tricas

| M√©trica | Descri√ß√£o | M√©dia ($\mu$) | Desvio Padr√£o ($\sigma$) | Veredito |
| :--- | :--- | :--- | :--- | :--- |
| **F1-Score (LeftOf)** | Precis√£o das rela√ß√µes horizontais | **0.962** | ¬± 0.015 | üü¢ **Excelente** |
| **F1-Score (Below)** | Precis√£o das rela√ß√µes verticais | **0.958** | ¬± 0.021 | üü¢ **Excelente** |
| **Sat Agg (Global)** | Satisfa√ß√£o m√©dia de todos os axiomas | **0.645** | ¬± 0.030 | üü° **Correto*** |
| **Query Q1** | Exist√™ncia de objeto complexo | **0.062** | ¬± 0.040 | ‚ö™ Raro |
| **Query Q2** | Exist√™ncia de Cone Verde "InBetween" | **0.120** | ¬± 0.080 | ‚ö™ Raro |
| **Query Q3** | Regra: Tri√¢ngulos Pr√≥ximos $\to$ Mesmo Tamanho | **0.991** | ¬± 0.005 | üü¢ **Aprendido** |

### 2. Interpreta√ß√£o dos Dados (O "Porqu√™" dos n√∫meros)

#### ‚úÖ O Sucesso da Generaliza√ß√£o (F1-Scores > 0.95)
Os resultados mais cr√≠ticos s√£o os **F1-Scores** para `LeftOf` e `Below`.
* O modelo treinou vendo objetos fixos (ex: um quadrado sempre na posi√ß√£o `0.2, 0.2`).
* No teste, ele viu objetos em posi√ß√µes totalmente novas e aleat√≥rias (ex: `0.8, 0.9`).
* **Conclus√£o:** O fato de manter F1 > 0.95 prova que a rede neural aprendeu a **fun√ß√£o matem√°tica** das coordenadas ($x_1 < x_2 \implies LeftOf$) e n√£o apenas decorou posi√ß√µes. A rede desacoplou a percep√ß√£o visual da l√≥gica simb√≥lica.

#### ‚ö†Ô∏è O Paradoxo da Satisfa√ß√£o Global (Sat Agg ‚âà 0.65)
Um observador desatento pode achar que 0.65 √© uma nota baixa. No entanto, em Logic Tensor Networks com dados aleat√≥rios, **isso √© o comportamento correto**.
* A Base de Conhecimento inclui perguntas existenciais complexas (ex: "Existe um Cone Verde entre dois objetos?").
* Em um cen√°rio gerado aleatoriamente, n√£o h√° garantia estat√≠stica de que essa combina√ß√£o espec√≠fica exista.
* Quando o cen√°rio **n√£o** tem um Cone Verde e o modelo retorna **0.0** (Falso), ele est√° **acertando a l√≥gica**. Isso reduz a m√©dia aritm√©tica da satisfa√ß√£o global, mas indica precis√£o do agente.

#### üß† Racioc√≠nio Derivado (Query Q3 ‚âà 0.99)
A Query Q3 √© uma regra condicional: *"Se dois tri√¢ngulos est√£o pr√≥ximos, eles t√™m o mesmo tamanho"*.
* O valor de **0.99** indica que o modelo aprendeu perfeitamente essa imposi√ß√£o.
* Isso demonstra a capacidade **Neuro-Simb√≥lica**: o modelo ajustou os embeddings dos tri√¢ngulos no espa√ßo latente para satisfazer uma regra que conecta "Posi√ß√£o" (`CloseTo`) com "Atributo" (`SameSize`).

---

## üöÄ Como Executar

### Pr√©-requisitos
* Python 3.8+
* Bibliotecas: `torch`, `ltn`, `numpy`, `matplotlib`

### Passos
1.  Clone o reposit√≥rio.
2.  Instale as depend√™ncias: `pip install ltn-torch`
3.  Execute o notebook `Trabalho_3_FIA.ipynb` em um ambiente Jupyter ou Google Colab.

---

*Desenvolvido com LTNtorch.*
